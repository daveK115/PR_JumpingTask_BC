{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acbe94db-7b58-4c75-8082-e4d176407cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: k12123854 (davidkla). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import wandb\n",
    "from jumping_task import JumpTaskEnv\n",
    "from simplemodel_v1 import SimpleModelV1\n",
    "from simplemodel_v2 import SimpleModelV2\n",
    "from simplemodel_v3 import SimpleModelV3\n",
    "from data_helpers import generate_imitation_data\n",
    "from data_helpers import generate_training_positions\n",
    "from data_helpers import prepare_observation_target_data\n",
    "from data_helpers import generate_augmented_data_horiz\n",
    "from data_helpers import generate_augmented_data_vert\n",
    "from data_helpers import generate_validation_positions_adjacent\n",
    "from data_helpers import generate_validation_positions_random\n",
    "from data_helpers import calculate_sampler_weights\n",
    "from training_helpers import hyperparameter_grid_search\n",
    "from training_helpers import train_model\n",
    "from evaluation_helpers import test_agent\n",
    "from misc_helpers import get_device\n",
    "from misc_helpers import setup_seed\n",
    "from misc_helpers import print_positions\n",
    "\n",
    "wandb.login()\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accaf428-16b2-4166-9920-6fc4281cb5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "imitation_data = generate_imitation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "35b7efdd-7757-4623-bd22-c190e4dbb456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wide grid\n",
    "training_positions = generate_training_positions()\n",
    "\n",
    "# tight grid\n",
    "# training_positions = generate_training_positions(min_obstacle_position=28,\n",
    "#                                 max_obstacle_position=38,\n",
    "#                                 min_floor_height=13,\n",
    "#                                 max_floor_height=17,\n",
    "#                                 positions_train_diff=2,\n",
    "#                                 heights_train_diff=2)\n",
    "\n",
    "# Random Train Split\n",
    "#training_positions = generate_training_positions(random_tasks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ecd9afb-8de0-41ee-a19d-202ae1534de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      " t v o o v t v o o v t v o o v t v o o v t v o o v t\n",
      " v o o o o v o o o o v o o o o v o o o o v o o o o v\n",
      " o o o o o o o o o o o o o o o o o o o o o o o o o o\n",
      " o o o o o o o o o o o o o o o o o o o o o o o o o o\n",
      " v o o o o v o o o o v o o o o v o o o o v o o o o v\n",
      " t v o o v t v o o v t v o o v t v o o v t v o o v t\n",
      " v o o o o v o o o o v o o o o v o o o o v o o o o v\n",
      " o o o o o o o o o o o o o o o o o o o o o o o o o o\n",
      " o o o o o o o o o o o o o o o o o o o o o o o o o o\n",
      " v o o o o v o o o o v o o o o v o o o o v o o o o v\n",
      " t v o o v t v o o v t v o o v t v o o v t v o o v t\n"
     ]
    }
   ],
   "source": [
    "validation_positions = generate_validation_positions_adjacent(training_positions, 20, 10, 45, 20)\n",
    "#validation_positions = generate_validation_positions_random(training_positions, n_positions=20)\n",
    "#validation_positions = []\n",
    "print(len(validation_positions))\n",
    "\n",
    "print_positions(training_positions, validation_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8602988-0054-464e-875b-9fcd45db07b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_observation_target_data(training_positions, imitation_data)\n",
    "x_val, y_val = prepare_observation_target_data(validation_positions, imitation_data)\n",
    "\n",
    "x_train_augmented, y_train_augmented = generate_augmented_data_horiz(x_train, y_train, 3, 3)\n",
    "#x_train_augmented, y_train_augmented = generate_augmented_data_vert(x_train_augmented, y_train_augmented, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d09ba866-767a-4108-99fb-377fafaa6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_weights_train = calculate_sampler_weights(y_train).to(device)\n",
    "sampler_train = WeightedRandomSampler(samples_weights_train, len(samples_weights_train))\n",
    "\n",
    "samples_weights_train_augmented = calculate_sampler_weights(y_train_augmented).to(device)\n",
    "sampler_train_augmented = WeightedRandomSampler(samples_weights_train_augmented, len(samples_weights_train_augmented))\n",
    "\n",
    "if len(validation_positions) > 0:\n",
    "    samples_weights_val = calculate_sampler_weights(y_val)\n",
    "    sampler_val = WeightedRandomSampler(samples_weights_val, len(samples_weights_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98bcc036-0ac1-42b4-a3f9-58ea077f5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(x_train).unsqueeze(1).to(device), torch.LongTensor(y_train).to(device))  # create your datset\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=sampler_train)\n",
    "\n",
    "train_dataset_augmented = TensorDataset(torch.Tensor(x_train_augmented).unsqueeze(1).to(device), torch.LongTensor(y_train_augmented).to(device))  # create your datset\n",
    "train_dataloader_augmented = DataLoader(train_dataset_augmented, batch_size=64, sampler=sampler_train_augmented)\n",
    "\n",
    "if len(validation_positions) > 0:\n",
    "    val_dataset = TensorDataset(torch.Tensor(x_val).unsqueeze(1).to(device), torch.LongTensor(y_val).to(device))  # create your datset\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, sampler=sampler_val)\n",
    "else:\n",
    "    val_dataset = None\n",
    "    val_dataloader = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522cc4f3-3ad6-453c-8ef5-6169a56cdf27",
   "metadata": {},
   "source": [
    "**Train single model (1 run)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63a7ad0-125d-4f83-ba70-30f3871ab4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SimpleModelV3(dropout_rate_conv=0.3, dropout_rate_fc=0.1)\n",
    "model = SimpleModelV3(dropout_rate_conv=0.0, dropout_rate_fc=0.0)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "run = wandb.init(\n",
    "    project=\"JumpingTask_BC\",\n",
    "    config={\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"architecture\": \"SimpleModelV3\",\n",
    "    \"dropout_rate_conv\": 0.0,\n",
    "    \"dropout_rate_fc\": 0.0,\n",
    "    \"weight_decay\": 0.0,\n",
    "    \"dataset\": \"Wide-Grid\",\n",
    "    \"batch_size\": 64,\n",
    "    \"validation_positions\": \"No validation\",\n",
    "    \"epochs\": 400,\n",
    "    }\n",
    ")\n",
    "\n",
    "train_model(model, optimizer, criterion, 300, train_dataloader, val_dataloader, validate=False, print_out=True)\n",
    "solved_total, solved_train, solved_val, solved_test = test_agent(model, device, training_positions, validation_positions, True)\n",
    "run.summary[\"solved_envs\"] = solved_total\n",
    "run.summary[\"solved_envs_train\"] = solved_train\n",
    "run.summary[\"solved_envs_val\"] = solved_val\n",
    "run.summary[\"solved_envs_test\"] = solved_test\n",
    "run.summary[\"validation_size\"] = len(validation_positions)\n",
    "run.log_model(path=\"best_model.pt\", name = \"model\")\n",
    "run.finish()\n",
    "\n",
    "print(f\"Solved {solved_total} out of 286 Environments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a491395-55b8-41e3-9783-628268c82fd6",
   "metadata": {},
   "source": [
    "**Train/Test mutiple models (50 runs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eaa005-c5c8-42c6-b408-2637206103e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)\n",
    "\n",
    "for i_run in range(0, 50):\n",
    "    model = SimpleModelV3(dropout_rate_conv=0.3, dropout_rate_fc=0.1)\n",
    "    #model = SimpleModelV3(dropout_rate_conv=0.0, dropout_rate_fc=0.0)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"JumpingTask_BC\",\n",
    "        name=f\"TestTight_{i_run+1}\",\n",
    "        config={\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"architecture\": \"SimpleModelV3\",\n",
    "        \"dropout_rate_conv\": 0.3,\n",
    "        \"dropout_rate_fc\": 0.1,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"dataset\": \"Tight-Grid\",\n",
    "        \"batch_size\": 64,\n",
    "        \"validation_positions\": \"No validation\",\n",
    "        \"epochs\": 400,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    train_model(model, optimizer, criterion, 400, train_dataloader, val_dataloader, validate=False, print_out=False)\n",
    "    solved_total, solved_train, solved_val, solved_test = test_agent(model, device, training_positions, validation_positions)\n",
    "    run.summary[\"solved_envs\"] = solved_total\n",
    "    run.summary[\"solved_envs_train\"] = solved_train\n",
    "    run.summary[\"solved_envs_val\"] = solved_val\n",
    "    run.summary[\"solved_envs_test\"] = solved_test\n",
    "    run.summary[\"validation_size\"] = len(validation_positions)\n",
    "    run.log_model(path=\"best_model.pt\", name = \"model\")\n",
    "    run.finish()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c39e0-38ed-4441-86f4-30944edd5dec",
   "metadata": {},
   "source": [
    "**Random-Grid Experiment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a81473-1aad-41e9-90fe-ae3aa3a725ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)\n",
    "\n",
    "for i_run in range(0, 50):\n",
    "    training_positions = generate_training_positions(random_tasks=True)\n",
    "    #validation_positions = generate_validation_positions_adjacent(training_positions, 20, 10, 45, 20)\n",
    "    #validation_positions = generate_validation_positions_random(training_positions, n_positions=20)\n",
    "    validation_positions = []\n",
    "\n",
    "    x_train, y_train = prepare_observation_target_data(training_positions, imitation_data)\n",
    "    x_val, y_val = prepare_observation_target_data(validation_positions, imitation_data)\n",
    "        \n",
    "    #x_train_augmented, y_train_augmented = generate_augmented_data_horiz(x_train, y_train, 3, 3)\n",
    "\n",
    "    samples_weights_train = calculate_sampler_weights(y_train).to(device)\n",
    "    sampler_train = WeightedRandomSampler(samples_weights_train, len(samples_weights_train))\n",
    "    \n",
    "    # samples_weights_train_augmented = calculate_sampler_weights(y_train_augmented).to(device)\n",
    "    # sampler_train_augmented = WeightedRandomSampler(samples_weights_train_augmented, len(samples_weights_train_augmented))\n",
    "\n",
    "    if len(validation_positions) > 0:\n",
    "        samples_weights_val = calculate_sampler_weights(y_val)\n",
    "        sampler_val = WeightedRandomSampler(samples_weights_val, len(samples_weights_val))\n",
    "\n",
    "    train_dataset = TensorDataset(torch.Tensor(x_train).unsqueeze(1).to(device), torch.LongTensor(y_train).to(device))  # create your datset\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=64, sampler=sampler_train)\n",
    "\n",
    "    # train_dataset_augmented = TensorDataset(torch.Tensor(x_train_augmented).unsqueeze(1).to(device), torch.LongTensor(y_train_augmented).to(device))  # create your datset\n",
    "    # train_dataloader_augmented = DataLoader(train_dataset_augmented, batch_size=64, sampler=sampler_train_augmented)\n",
    "\n",
    "    if len(validation_positions) > 0:\n",
    "        val_dataset = TensorDataset(torch.Tensor(x_val).unsqueeze(1).to(device), torch.LongTensor(y_val).to(device))  # create your datset\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=64, sampler=sampler_val)\n",
    "    else:\n",
    "        val_dataloader = None\n",
    "        val_dataset = None\n",
    "\n",
    "    model = SimpleModelV3(dropout_rate_conv=0.3, dropout_rate_fc=0.1)\n",
    "    #model = SimpleModelV3(dropout_rate_conv=0.0, dropout_rate_fc=0.0)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.0001)\n",
    "    #optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "    run = wandb.init(\n",
    "        project=\"JumpingTask_BC\",\n",
    "        name=f\"TestRandom_{i_run+1}\",\n",
    "        config={\n",
    "        \"learning_rate\": 0.0005,\n",
    "        \"architecture\": \"SimpleModelV3\",\n",
    "        \"dropout_rate_conv\": 0.3,\n",
    "        \"dropout_rate_fc\": 0.1,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"dataset\": \"Random-Grid\",\n",
    "        \"batch_size\": 64,\n",
    "        \"validation_positions\": \"No validation\",\n",
    "        \"epochs\": 400,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    train_model(model, optimizer, criterion, 400, train_dataloader, val_dataloader, validate=False, print_out=False)\n",
    "    solved_total, solved_train, solved_val, solved_test = test_agent(model, device, training_positions, validation_positions)\n",
    "    run.summary[\"solved_envs\"] = solved_total\n",
    "    run.summary[\"solved_envs_train\"] = solved_train\n",
    "    run.summary[\"solved_envs_val\"] = solved_val\n",
    "    run.summary[\"solved_envs_test\"] = solved_test\n",
    "    run.summary[\"validation_size\"] = len(validation_positions)\n",
    "    run.log_model(path=\"best_model.pt\", name = \"model\")\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199246-fa8e-4e13-8099-181e5d2a7afd",
   "metadata": {},
   "source": [
    "**Search for dropout rates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af4ecea-e3f9-4c0f-9d88-3cb7123348ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_rates_conv = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "dropout_rates_fc = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "weight_decay_factor = [0.0001, 0.001, 0.01]\n",
    "    \n",
    "for rate_conv in dropout_rates_conv:\n",
    "        for rate_fc in dropout_rates_fc:\n",
    "            for weight_decay in weight_decay_factor:\n",
    "                setup_seed(42)\n",
    "                for i_run in range(0, 5):\n",
    "                    model = SimpleModelV3(dropout_rate_conv=rate_conv, dropout_rate_fc=rate_fc)\n",
    "                    model = model.to(device)\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=weight_decay)\n",
    "                \n",
    "                    run = wandb.init(\n",
    "                        project=\"JumpingTask_BC\",\n",
    "                        name=f\"SearchDropoutRateWide_{i_run+1}\",\n",
    "                        config={\n",
    "                        \"learning_rate\": 0.0005,\n",
    "                     .   \"architecture\": \"SimpleModelV3\",\n",
    "                        \"dropout_rate_conv\": rate_conv,\n",
    "                        \"dropout_rate_fc\": rate_fc,\n",
    "                        \"weight_decay\": weight_decay,\n",
    "                        \"dataset\": \"Wide-Grid\",\n",
    "                        \"batch_size\": 64,\n",
    "                        \"validation_positions\": \"No validation\",\n",
    "                        \"epochs\": 400,\n",
    "                        }\n",
    "                    )\n",
    "                    \n",
    "                    train_model(model, optimizer, criterion, 400, train_dataloader, val_dataloader, validate=False, print_out=False)\n",
    "                    solved_total, solved_train, solved_val, solved_test = test_agent(model, device, training_positions, validation_positions)\n",
    "                    run.summary[\"solved_envs\"] = solved_total\n",
    "                    run.summary[\"solved_envs_train\"] = solved_train\n",
    "                    run.summary[\"solved_envs_val\"] = solved_val\n",
    "                    run.summary[\"solved_envs_test\"] = solved_test\n",
    "                    run.summary[\"validation_size\"] = len(validation_positions)\n",
    "                    run.log_model(path=\"best_model.pt\", name = \"model\")\n",
    "                    run.finish()\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
